{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interchange.persistence.file import FileStorage\n",
    "from interchange.visa import transform, extract, clean, calculate, interchange, store\n",
    "\n",
    "layer = FileStorage.Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = \"SBSA\"\n",
    "file_id = \"B6781ADDCFE0CD800BFA2968A6ED2816\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_layer = layer.STAGING\n",
    "target_layer = layer.STAGING\n",
    "client_id = client_id\n",
    "file_id = file_id\n",
    "transactions_subdir = \"300-SMS_CLN_MESSAGES\"\n",
    "calculated_subdir = \"400-SMS_CAL_MESSAGES\"\n",
    "target_subdir = \"500-SMS_ITX_MESSAGES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from interchange.logs.logger import Logger\n",
    "from interchange.persistence.database import Database\n",
    "from interchange.persistence.file import FileStorage\n",
    "\n",
    "\n",
    "log = Logger(__name__)\n",
    "fs = FileStorage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCIONES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_file_data(client_id: str, file_id: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Get key metadata associated to an interchange file.\n",
    "    \"\"\"\n",
    "    db = Database()\n",
    "    fd = db.read_records(\n",
    "        table_name=\"file_control\",\n",
    "        fields=[\n",
    "            \"brand_id\",\n",
    "            \"file_type\",\n",
    "            \"file_processing_date\",\n",
    "        ],\n",
    "        where={\"client_id\": client_id, \"file_id\": file_id},\n",
    "    )\n",
    "    fd[\"file_processing_date\"] = pd.to_datetime(\n",
    "        fd[\"file_processing_date\"], format=\"%Y-%m-%d\"\n",
    "    ).dt.date\n",
    "    return fd.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_visa_rule_definitions(file_date: date, type_record: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get Visa's interchange rule assignment criteria for the file's processing date.\n",
    "    \"\"\"\n",
    "    db = Database()\n",
    "    df = db.read_records(\n",
    "        table_name=\"visa_rules_2\",\n",
    "        fields=[\n",
    "            \"region_country_code\",\n",
    "            \"valid_from\",\n",
    "            \"valid_until\",\n",
    "            \"intelica_id\",\n",
    "            \"fee_descriptor\",\n",
    "            \"fee_currency\",\n",
    "            \"fee_variable\",\n",
    "            \"fee_fixed\",\n",
    "            \"fee_min\",\n",
    "            \"fee_cap\",\n",
    "            \"business_mode\",\n",
    "            \"issuer_country\",\n",
    "            \"issuer_region\",\n",
    "            \"technology_indicator\",\n",
    "            \"product_id\",\n",
    "            \"fast_funds\",\n",
    "            \"travel_indicator\",\n",
    "            \"b2b_program_id\",\n",
    "            \"account_funding_source\",\n",
    "            \"nnss_indicator\",\n",
    "            \"product_subtype\",\n",
    "            \"transaction_code\",\n",
    "            \"transaction_code_qualifier\",\n",
    "            \"issuer_bin_8\",\n",
    "            \"acquirer_bin\",\n",
    "            \"acquirer_business_id\",\n",
    "            \"transaction_amount_currency\",\n",
    "            \"transaction_amount\",\n",
    "            \"acquirer_country\",\n",
    "            \"acquirer_region\",\n",
    "            \"merchant_country_code\",\n",
    "            \"merchant_country_region\",\n",
    "            \"merchant_category_code\",\n",
    "            \"requested_payment_service\",\n",
    "            \"usage_code\",\n",
    "            \"authorization_characteristics_indicator\",\n",
    "            \"authorization_code\",\n",
    "            \"pos_terminal_capability\",\n",
    "            \"cardholder_id_method\",\n",
    "            \"pos_entry_mode\",\n",
    "            \"timeliness\",\n",
    "            \"reimbursement_attribute\",\n",
    "            \"special_condition_indicator\",\n",
    "            \"fee_program_indicator\",\n",
    "            \"moto_eci_indicator\",\n",
    "            \"acceptance_terminal_indicator\",\n",
    "            \"prepaid_card_indicator\",\n",
    "            \"pos_environment_code\",\n",
    "            \"business_format_code\",\n",
    "            \"business_application_id\",\n",
    "            \"type_purchase\",\n",
    "            \"network_identification_code\",\n",
    "            \"message_reason_code\",\n",
    "            \"surcharge_amount\",\n",
    "            \"authorized_amount\",\n",
    "            \"authorization_response_code\",\n",
    "            \"merchant_verification_value\",\n",
    "            \"dynamic_currency_conversion_indicator\",\n",
    "            \"cvv2_result_code\",\n",
    "            \"national_tax_indicator\",\n",
    "            \"merchant_vat\",\n",
    "            \"summary_commodity\",\n",
    "            \"processing_code_transaction_type\",\n",
    "            \"point_of_service_condition_code\",\n",
    "        ],\n",
    "    )\n",
    "    int_cols = [\"intelica_id\"]\n",
    "    numeric_cols = [\"fee_variable\", \"fee_fixed\", \"fee_min\", \"fee_cap\"]\n",
    "    date_cols = [\"valid_from\", \"valid_until\"]\n",
    "    df[int_cols] = df[int_cols].apply(\n",
    "        pd.to_numeric, downcast=\"integer\", errors=\"coerce\"\n",
    "    )\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(\n",
    "            df[col].str.slice(0, 10), format=\"%Y-%m-%d\", errors=\"coerce\"\n",
    "        ).dt.date\n",
    "    df[date_cols] = df[date_cols].fillna(date.today())\n",
    "    df_valid = df[(file_date >= df[\"valid_from\"]) & (file_date <= df[\"valid_until\"])]\n",
    "    df_valid = df_valid.sort_values([\"region_country_code\", \"intelica_id\"])\n",
    "    match type_record:\n",
    "        case \"draft\":\n",
    "            df_valid.drop(\n",
    "                columns=[\n",
    "                    \"acquirer_country\",\n",
    "                    \"acquirer_region\",\n",
    "                    \"processing_code_transaction_type\",\n",
    "                    \"point_of_service_condition_code\",\n",
    "                ],\n",
    "                inplace=True,\n",
    "            )\n",
    "            df_valid.rename(\n",
    "                columns={\n",
    "                    \"account_funding_source\": \"funding_source\",\n",
    "                    \"acquirer_bin\": \"account_reference_number_acquiring_identifier\",\n",
    "                    \"cvv2_result_code\": \"cvv_result_code\",\n",
    "                    \"dynamic_currency_conversion_indicator\": \"dcc_indicator\",\n",
    "                    \"merchant_country_code\": \"jurisdiction_country\",\n",
    "                    \"merchant_country_region\": \"jurisdiction_region\",\n",
    "                    \"merchant_vat\": \"merchant_vat_registration_number\",\n",
    "                    \"moto_eci_indicator\": \"moto_ec_indicator\",\n",
    "                    \"national_tax_indicator\": \"national_tax_included\",\n",
    "                    \"pos_environment_code\": \"pos_environment\",\n",
    "                    \"pos_terminal_capability\": \"pos_terminal_capacity\",\n",
    "                    \"special_condition_indicator\": \"special_condition_indicator_merchant_draft_indicator\",\n",
    "                    \"summary_commodity\": \"summary_commodity_code\",\n",
    "                    \"transaction_amount\": \"source_amount\",\n",
    "                    \"transaction_code_qualifier\": \"draft_code_qualifier_0\",\n",
    "                    \"transaction_code\": \"draft_code\",\n",
    "                    \"type_purchase\": \"type_of_purchase\",\n",
    "                },\n",
    "                inplace=True,\n",
    "            )\n",
    "            return df_valid\n",
    "        case \"sms\":\n",
    "            df_valid.drop(\n",
    "                columns=[\n",
    "                    \"acquirer_country\",\n",
    "                    \"acquirer_region\",\n",
    "                    \"authorized_amount\",\n",
    "                    \"business_format_code\",\n",
    "                    \"merchant_vat\",\n",
    "                    \"national_tax_indicator\",\n",
    "                    \"prepaid_card_indicator\",\n",
    "                    \"summary_commodity\",\n",
    "                    \"transaction_amount_currency\",\n",
    "                    \"transaction_code_qualifier\",\n",
    "                    \"type_purchase\",\n",
    "                ],\n",
    "                inplace=True,\n",
    "            )\n",
    "            df_valid.rename(\n",
    "                columns={\n",
    "                    \"account_funding_source\": \"funding_source\",\n",
    "                    \"acceptance_terminal_indicator\": \"pos_terminal_type\",\n",
    "                    \"acquirer_business_id\": \"acquirer_business_id_sms\",\n",
    "                    \"authorization_characteristics_indicator\": \"authorization_characteristics_indicator_sms\",\n",
    "                    \"authorization_code\": \"authorization_code_valid\",\n",
    "                    \"authorization_response_code\": \"response_code\",\n",
    "                    \"business_application_id\": \"business_application_identifier\",\n",
    "                    \"cardholder_id_method\": \"customer_identification_method\",\n",
    "                    \"cvv2_result_code\": \"cvv_result_code_sms\",\n",
    "                    \"dynamic_currency_conversion_indicator\": \"dcc_indicator_sms\",\n",
    "                    \"fee_program_indicator\": \"fee_program_indicator_sms\",\n",
    "                    \"merchant_category_code\": \"merchant's_type\",\n",
    "                    \"merchant_country_code\": \"jurisdiction_country\",\n",
    "                    \"merchant_country_region\": \"jurisdiction_region\",\n",
    "                    \"merchant_verification_value\": \"mvv_code\",\n",
    "                    \"message_reason_code\": \"message_reason_code_sms\",\n",
    "                    \"moto_eci_indicator\": \"mail_telephone_or_electronic_commerce_indicator\",\n",
    "                    \"network_identification_code\": \"network_id\",\n",
    "                    \"point_of_service_condition_code\": \"pos_condition_code\",\n",
    "                    \"pos_environment_code\": \"recurring_payment_indicator_flag\",\n",
    "                    \"pos_entry_mode\": \"pos_entry_mode_sms\",\n",
    "                    \"pos_terminal_capability\": \"pos_terminal_entry_capability\",\n",
    "                    \"reimbursement_attribute\": \"reimbursement_attribute_sms\",\n",
    "                    \"special_condition_indicator\": \"chargeback_special_condition_merchant_indicator\",\n",
    "                    \"summary_commodity\": \"summary_commodity_code\",\n",
    "                    \"surcharge_amount\": \"surcharge_amount_sms\",\n",
    "                    \"transaction_amount\": \"source_amount\",\n",
    "                    \"transaction_code_qualifier\": \"draft_code_qualifier_0\",\n",
    "                    \"transaction_code\": \"transaction_code_sms\",\n",
    "                    \"usage_code\": \"usage_code_sms\",\n",
    "                },\n",
    "                inplace=True,\n",
    "            )\n",
    "            return df_valid\n",
    "        case _:\n",
    "            raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_exchange_rates(file_date: date, brand: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get the exchange rates valid for the file's processing date and brand.\n",
    "    \"\"\"\n",
    "    date_string = file_date.strftime(\"%Y-%m-%d\")\n",
    "    db = Database()\n",
    "    df = db.read_records(\n",
    "        table_name=\"exchange_rate\",\n",
    "        fields=[\n",
    "            \"currency_from\",\n",
    "            \"currency_to\",\n",
    "            \"currency_from_code\",\n",
    "            \"currency_to_code\",\n",
    "            \"exchange_value\",\n",
    "        ],\n",
    "        where={\"brand\": brand, \"rate_date\": date_string},\n",
    "    )\n",
    "    df[\"exchange_value\"] = df[\"exchange_value\"].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_condition_default(\n",
    "    condition_name: str,\n",
    "    condition_value: str,\n",
    "    batch: pd.DataFrame,\n",
    "    column_group_space: list[str],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Checks conditions that have a specific value.\n",
    "    \"\"\"\n",
    "    batch = batch.copy()\n",
    "    condition_value = condition_value.strip().upper()\n",
    "    condition_value = condition_value.replace(\"SPACE\", \" \")\n",
    "    value_list = condition_value.split(\",\")\n",
    "    valid_values = []\n",
    "    not_valid_values = []\n",
    "    for value in value_list:\n",
    "        not_keyword_flag = False\n",
    "        if \"NOT:\" in value:\n",
    "            value = value.replace(\"NOT:\", \"\")\n",
    "            not_keyword_flag = True\n",
    "        filled_range = []\n",
    "        if \"-\" in value:\n",
    "            range_low, range_high = value.split(\"-\", maxsplit=1)\n",
    "            filled_range = list(range(int(range_low), int(range_high) + 1))\n",
    "            filled_range = list(map(str, filled_range))\n",
    "        reformatted_values = filled_range or [value]\n",
    "        match not_keyword_flag:\n",
    "            case False:\n",
    "                valid_values.extend(reformatted_values)\n",
    "            case True:\n",
    "                not_valid_values.extend(reformatted_values)\n",
    "\n",
    "    temp_col = batch[condition_name]\n",
    "    if condition_name in column_group_space:\n",
    "        batch[\"_normalized\"] = temp_col.astype(str)\n",
    "    else:\n",
    "        temp_col = temp_col.astype(str).str.strip()\n",
    "        temp_col = temp_col.mask(temp_col.str.len() == 0, \"BLANK\")\n",
    "        batch[\"_normalized\"] = temp_col\n",
    "\n",
    "    filter = batch\n",
    "    if valid_values:\n",
    "        filter = filter[filter[\"_normalized\"].isin(valid_values)]\n",
    "    if not_valid_values:\n",
    "        filter = filter[~filter[\"_normalized\"].isin(not_valid_values)]\n",
    "    filter = filter.drop(columns=\"_normalized\")\n",
    "\n",
    "    return filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_condition_greater_less(\n",
    "    condition_name: str, condition_value: str, batch: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Check numeric conditions where a value falls in a specified range.\n",
    "    \"\"\"\n",
    "    if any(x in condition_value for x in [\"<\", \">\", \"=\"]):\n",
    "        query_condition = f\"{condition_name} \" + condition_value.replace(\n",
    "            \"<=\", \"<= \"\n",
    "        ).replace(\">=\", \">= \").replace(\">\", \"> \").replace(\"<\", \"< \")\n",
    "\n",
    "        filter = batch.query(query_condition)\n",
    "    elif any(x in condition_value for x in [\"BETWEEN\", \"AND\"]):\n",
    "        range_low, range_high = list(\n",
    "            map(\n",
    "                float,\n",
    "                condition_value.replace(\" \", \"\")\n",
    "                .replace(\"BETWEEN\", \"\")\n",
    "                .split(\"AND\", maxsplit=1),\n",
    "            )\n",
    "        )\n",
    "        filter = batch[\n",
    "            batch[condition_name]\n",
    "            .astype(float)\n",
    "            .between(range_low, range_high, inclusive=\"both\")\n",
    "        ]\n",
    "    elif condition_value.replace(\".\", \"\", 1).isdigit():\n",
    "        numeric_value = float(condition_value)\n",
    "        filter = batch[batch[condition_name].astype(float) == numeric_value]\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_condition_amount_currency(\n",
    "    condition_name: str, string_range: str, batch: pd.DataFrame, rates: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Check currency amount conditions where a value falls in a specified range.\n",
    "    \"\"\"\n",
    "    condition_target_fields = {\n",
    "        \"source_amount\": \"source_currency_code_alphabetic\",\n",
    "    }\n",
    "    target_currency, string_range = string_range.split(\",\", maxsplit=1)\n",
    "    target_rates = rates[rates[\"currency_to\"] == target_currency]\n",
    "    filter = pd.merge(\n",
    "        left=batch,\n",
    "        right=target_rates[[\"currency_from\", \"exchange_value\"]],\n",
    "        how=\"left\",\n",
    "        left_on=condition_target_fields[condition_name],\n",
    "        right_on=\"currency_from\",\n",
    "    )\n",
    "    filter.loc[\n",
    "        filter[condition_target_fields[condition_name]] == target_currency,\n",
    "        \"exchange_value\",\n",
    "    ] = 1\n",
    "    filter[\"comparison_value\"] = filter[condition_name] * filter[\"exchange_value\"]\n",
    "\n",
    "    if any(x in string_range for x in [\"<\", \">\", \"=\"]):\n",
    "        query_condition = f\"comparison_value \" + string_range.replace(\n",
    "            \"<=\", \"<= \"\n",
    "        ).replace(\">=\", \">= \").replace(\">\", \"> \").replace(\"<\", \"< \")\n",
    "\n",
    "        filter = filter.query(query_condition)\n",
    "    elif any(x in string_range for x in [\"BETWEEN\", \"AND\"]):\n",
    "        range_low, range_high = list(\n",
    "            map(\n",
    "                float,\n",
    "                string_range.replace(\" \", \"\")\n",
    "                .replace(\"BETWEEN\", \"\")\n",
    "                .split(\"AND\", maxsplit=1),\n",
    "            )\n",
    "        )\n",
    "        filter = filter[\n",
    "            filter[\"comparison_value\"].between(range_low, range_high, inclusive=\"both\")\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    return filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _apply_condition(\n",
    "    condition_name: str, condition_value: str, batch: pd.DataFrame, rates: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean, check and apply condition to a batch of transactions.\n",
    "    \"\"\"\n",
    "    # If there is no condition, return the same batch of transactions.\n",
    "    condition_value = condition_value.replace(\" \", \"\").upper()\n",
    "    if condition_value in (\"\", \"NAN\", \"NONE\"):\n",
    "        return batch\n",
    "    # Otherwise, evaluate the condition.\n",
    "    column_group_greater_less = [\n",
    "        \"surcharge_amount\",\n",
    "        \"surcharge_amount_sms\",\n",
    "        \"timeliness\",\n",
    "    ]\n",
    "    column_group_amount_currency = [\n",
    "        \"source_amount\",\n",
    "    ]\n",
    "    column_group_space = [\n",
    "        \"nnss_indicator\",\n",
    "        \"cardholder_id_method\",\n",
    "        \"moto_eci_indicator\",\n",
    "        \"acceptance_terminal_indicator\",\n",
    "        \"merchant_vat\",\n",
    "    ]\n",
    "\n",
    "    match condition_name:\n",
    "        case name if name in column_group_greater_less:\n",
    "            result = _apply_condition_greater_less(\n",
    "                condition_name, condition_value, batch\n",
    "            )\n",
    "        case name if name in column_group_amount_currency:\n",
    "            result = _apply_condition_amount_currency(\n",
    "                condition_name, condition_value, batch, rates\n",
    "            )\n",
    "        case _:\n",
    "            result = _apply_condition_default(\n",
    "                condition_name, condition_value, batch, column_group_space\n",
    "            )\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate_interchange_fees(\n",
    "    transactions: pd.DataFrame,\n",
    "    rules: pd.DataFrame,\n",
    "    rates: pd.DataFrame,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Evaluate interchange fee criteria for a dataset of transactions.\n",
    "    \"\"\"\n",
    "    # Filter rule definitions to only jurisdictions present in data.\n",
    "    jurisdiction_list = transactions[\"jurisdiction_assigned\"].unique()\n",
    "    rules_to_evaluate = rules[rules[\"region_country_code\"].isin(jurisdiction_list)]\n",
    "    # Initialize rule identifier fields.\n",
    "    transactions[\"interchange_region_country_code\"] = \"\"\n",
    "    transactions[\"interchange_intelica_id\"] = -1\n",
    "    transactions[\"interchange_fee_descriptor\"] = \"\"\n",
    "    transactions[\"interchange_fee_currency\"] = \"\"\n",
    "    transactions[\"interchange_fee_variable\"] = 0.0\n",
    "    transactions[\"interchange_fee_fixed\"] = 0.0\n",
    "    transactions[\"interchange_fee_min\"] = 0.0\n",
    "    transactions[\"interchange_fee_cap\"] = 0.0\n",
    "    # Iterate through each rule definition.\n",
    "    conditions_to_skip = [\n",
    "        \"region_country_code\",\n",
    "        \"valid_from\",\n",
    "        \"valid_until\",\n",
    "        \"intelica_id\",\n",
    "        \"fee_descriptor\",\n",
    "        \"fee_currency\",\n",
    "        \"fee_variable\",\n",
    "        \"fee_fixed\",\n",
    "        \"fee_min\",\n",
    "        \"fee_cap\",\n",
    "    ]\n",
    "    update_columns = [\n",
    "        \"region_country_code\",\n",
    "        \"intelica_id\",\n",
    "        \"fee_descriptor\",\n",
    "        \"fee_currency\",\n",
    "        \"fee_variable\",\n",
    "        \"fee_fixed\",\n",
    "        \"fee_min\",\n",
    "        \"fee_cap\",\n",
    "    ]\n",
    "    for _, rule in rules_to_evaluate.iterrows():\n",
    "        # Step 1: Filter unprocessed transactions and decide to break, skip or evaluate.\n",
    "        next_batch = transactions[\n",
    "            (transactions[\"interchange_intelica_id\"] == -1)\n",
    "            & (transactions[\"jurisdiction_assigned\"] == rule[\"region_country_code\"])\n",
    "        ]\n",
    "        if next_batch.empty:\n",
    "            continue\n",
    "        # Step 2: Iterate through each condition in the rule and apply its condition.\n",
    "        conditions = [\n",
    "            str(cond_name)\n",
    "            for cond_name in rule.index.to_list()\n",
    "            if cond_name not in conditions_to_skip and rule[cond_name] != \"\"\n",
    "        ]\n",
    "        for condition in conditions:\n",
    "            next_batch = _apply_condition(condition, rule[condition], next_batch, rates)\n",
    "            if next_batch.empty:\n",
    "                break\n",
    "        # Step 3: Update transaction table with batch results.\n",
    "        if not next_batch.empty:\n",
    "            for column in update_columns:\n",
    "                next_batch.loc[:, f\"interchange_{column}\"] = rule[column]\n",
    "            transactions.update(\n",
    "                next_batch[[f\"interchange_{c}\" for c in update_columns]]\n",
    "            )\n",
    "\n",
    "    columns_to_return = [f\"interchange_{c}\" for c in update_columns]\n",
    "    columns_to_return = [\n",
    "        \"source_currency_code_alphabetic\",\n",
    "        \"source_amount\",\n",
    "    ] + columns_to_return\n",
    "    return transactions[columns_to_return]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_interchange_fees(\n",
    "    fee_parameters: pd.DataFrame, rates: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate interchange fee amounts depending on the assigned fee parameters.\n",
    "    \"\"\"\n",
    "    stage = pd.merge(\n",
    "        left=fee_parameters,\n",
    "        right=rates[[\"currency_from\", \"currency_to\", \"exchange_value\"]],\n",
    "        how=\"left\",\n",
    "        left_on=[\"source_currency_code_alphabetic\", \"interchange_fee_currency\"],\n",
    "        right_on=[\"currency_from\", \"currency_to\"],\n",
    "    )\n",
    "    stage.loc[\n",
    "        stage[\"source_currency_code_alphabetic\"] == stage[\"interchange_fee_currency\"],\n",
    "        \"exchange_value\",\n",
    "    ] = 1\n",
    "    stage.drop(columns=[\"currency_from\", \"currency_to\"], inplace=True)\n",
    "\n",
    "    stage[\"interchange_fee_variable\"] = stage[\"interchange_fee_variable\"].fillna(0)\n",
    "    cur_cols = [\"interchange_fee_fixed\", \"interchange_fee_min\", \"interchange_fee_cap\"]\n",
    "    stage[cur_cols] = stage[cur_cols].replace(to_replace=0, value=np.nan)\n",
    "    for col in cur_cols:\n",
    "        stage[f\"{col}_source\"] = stage[col] * stage[\"exchange_value\"]\n",
    "        match col:\n",
    "            case \"interchange_fee_fixed\":\n",
    "                stage[f\"{col}_source\"] = stage[f\"{col}_source\"].fillna(0)\n",
    "            case \"interchange_fee_min\":\n",
    "                stage[f\"{col}_source\"] = stage[f\"{col}_source\"].fillna(-np.inf)\n",
    "            case \"interchange_fee_cap\":\n",
    "                stage[f\"{col}_source\"] = stage[f\"{col}_source\"].fillna(+np.inf)\n",
    "\n",
    "    stage[\"interchange_fee_amount\"] = (\n",
    "        stage[\"source_amount\"] * stage[\"interchange_fee_variable\"]\n",
    "        + stage[\"interchange_fee_fixed_source\"]\n",
    "    )\n",
    "    stage[\"interchange_fee_amount\"] = stage[\n",
    "        [\"interchange_fee_amount\", \"interchange_fee_min_source\"]\n",
    "    ].max(axis=1)\n",
    "    stage[\"interchange_fee_amount\"] = stage[\n",
    "        [\"interchange_fee_amount\", \"interchange_fee_cap_source\"]\n",
    "    ].min(axis=1)\n",
    "\n",
    "    result = stage.drop(columns=[\"source_currency_code_alphabetic\", \"source_amount\"])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 11:55:56,105 :: PID 16544 :: TID 28624 :: database._create_connection :: Line 33 :: DEBUG :: Connected to SQLite database\n",
      "2025-12-02 11:55:56,105 :: PID 16544 :: TID 28624 :: database.read_records :: Line 138 :: DEBUG :: Attempting to execute SELECT SQL statement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 11:55:56,115 :: PID 16544 :: TID 28624 :: database._execute :: Line 57 :: DEBUG :: SQL statement executed successfully\n",
      "2025-12-02 11:55:56,158 :: PID 16544 :: TID 28624 :: database._close_connection :: Line 44 :: DEBUG :: Closed connection to SQLite database\n"
     ]
    }
   ],
   "source": [
    "transactions = fs.read_parquet(\n",
    "    origin_layer,\n",
    "    client_id,\n",
    "    file_id,\n",
    "    subdir=transactions_subdir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 11:55:57,478 :: PID 16544 :: TID 28624 :: database._create_connection :: Line 33 :: DEBUG :: Connected to SQLite database\n",
      "2025-12-02 11:55:57,481 :: PID 16544 :: TID 28624 :: database.read_records :: Line 138 :: DEBUG :: Attempting to execute SELECT SQL statement\n",
      "2025-12-02 11:55:57,485 :: PID 16544 :: TID 28624 :: database._execute :: Line 57 :: DEBUG :: SQL statement executed successfully\n",
      "2025-12-02 11:55:57,487 :: PID 16544 :: TID 28624 :: database._close_connection :: Line 44 :: DEBUG :: Closed connection to SQLite database\n"
     ]
    }
   ],
   "source": [
    "calculated = fs.read_parquet(\n",
    "    origin_layer,\n",
    "    client_id,\n",
    "    file_id,\n",
    "    subdir=calculated_subdir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = transactions.join(calculated, how=\"left\", lsuffix=\"_sms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 11:56:03,067 :: PID 16544 :: TID 28624 :: database._create_connection :: Line 33 :: DEBUG :: Connected to SQLite database\n",
      "2025-12-02 11:56:03,067 :: PID 16544 :: TID 28624 :: database.read_records :: Line 138 :: DEBUG :: Attempting to execute SELECT SQL statement\n",
      "2025-12-02 11:56:03,067 :: PID 16544 :: TID 28624 :: database._execute :: Line 57 :: DEBUG :: SQL statement executed successfully\n",
      "2025-12-02 11:56:03,098 :: PID 16544 :: TID 28624 :: database._close_connection :: Line 44 :: DEBUG :: Closed connection to SQLite database\n",
      "2025-12-02 11:56:03,102 :: PID 16544 :: TID 28624 :: database._create_connection :: Line 33 :: DEBUG :: Connected to SQLite database\n",
      "2025-12-02 11:56:03,103 :: PID 16544 :: TID 28624 :: database.read_records :: Line 138 :: DEBUG :: Attempting to execute SELECT SQL statement\n",
      "2025-12-02 11:56:03,105 :: PID 16544 :: TID 28624 :: database._execute :: Line 57 :: DEBUG :: SQL statement executed successfully\n",
      "2025-12-02 11:56:03,159 :: PID 16544 :: TID 28624 :: database._close_connection :: Line 44 :: DEBUG :: Closed connection to SQLite database\n"
     ]
    }
   ],
   "source": [
    "file_data = _get_file_data(client_id, file_id)\n",
    "rules_data = _get_visa_rule_definitions(\n",
    "    file_data[\"file_processing_date\"], type_record=\"sms\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_country_code',\n",
       " 'valid_from',\n",
       " 'valid_until',\n",
       " 'intelica_id',\n",
       " 'fee_descriptor',\n",
       " 'fee_currency',\n",
       " 'fee_variable',\n",
       " 'fee_fixed',\n",
       " 'fee_min',\n",
       " 'fee_cap',\n",
       " 'business_mode',\n",
       " 'issuer_country',\n",
       " 'issuer_region',\n",
       " 'technology_indicator',\n",
       " 'product_id',\n",
       " 'fast_funds',\n",
       " 'travel_indicator',\n",
       " 'b2b_program_id',\n",
       " 'funding_source',\n",
       " 'nnss_indicator',\n",
       " 'product_subtype',\n",
       " 'transaction_code_sms',\n",
       " 'issuer_bin_8',\n",
       " 'acquirer_bin',\n",
       " 'acquirer_business_id_sms',\n",
       " 'source_amount',\n",
       " 'jurisdiction_country',\n",
       " 'jurisdiction_region',\n",
       " \"merchant's_type\",\n",
       " 'requested_payment_service',\n",
       " 'usage_code_sms',\n",
       " 'authorization_characteristics_indicator_sms',\n",
       " 'authorization_code_valid',\n",
       " 'pos_terminal_entry_capability',\n",
       " 'customer_identification_method',\n",
       " 'pos_entry_mode_sms',\n",
       " 'timeliness',\n",
       " 'reimbursement_attribute_sms',\n",
       " 'chargeback_special_condition_merchant_indicator',\n",
       " 'fee_program_indicator_sms',\n",
       " 'mail_telephone_or_electronic_commerce_indicator',\n",
       " 'pos_terminal_type',\n",
       " 'recurring_payment_indicator_flag',\n",
       " 'business_application_identifier',\n",
       " 'network_id',\n",
       " 'message_reason_code_sms',\n",
       " 'surcharge_amount_sms',\n",
       " 'response_code',\n",
       " 'mvv_code',\n",
       " 'dcc_indicator_sms',\n",
       " 'cvv_result_code_sms',\n",
       " 'processing_code_transaction_type',\n",
       " 'pos_condition_code']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-02 11:56:47,239 :: PID 16544 :: TID 28624 :: database._create_connection :: Line 33 :: DEBUG :: Connected to SQLite database\n",
      "2025-12-02 11:56:47,241 :: PID 16544 :: TID 28624 :: database.read_records :: Line 138 :: DEBUG :: Attempting to execute SELECT SQL statement\n",
      "2025-12-02 11:56:47,719 :: PID 16544 :: TID 28624 :: database._execute :: Line 57 :: DEBUG :: SQL statement executed successfully\n",
      "2025-12-02 11:56:47,873 :: PID 16544 :: TID 28624 :: database._close_connection :: Line 44 :: DEBUG :: Closed connection to SQLite database\n"
     ]
    }
   ],
   "source": [
    "rates = _get_exchange_rates(file_data[\"file_processing_date\"], brand=\"VISA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "fee_parameters = _evaluate_interchange_fees(merged_data, rules_data, rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "interchange_df = _calculate_interchange_fees(fee_parameters, rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 13:54:21,694 :: PID 20676 :: TID 29572 :: file.write_parquet :: Line 128 :: DEBUG :: Writing SBSA file B6781ADDCFE0CD800BFA2968A6ED2816 to parquet\n",
      "2025-12-01 13:54:21,699 :: PID 20676 :: TID 29572 :: database._create_connection :: Line 33 :: DEBUG :: Connected to SQLite database\n",
      "2025-12-01 13:54:21,701 :: PID 20676 :: TID 29572 :: database.read_records :: Line 138 :: DEBUG :: Attempting to execute SELECT SQL statement\n",
      "2025-12-01 13:54:21,702 :: PID 20676 :: TID 29572 :: database._execute :: Line 57 :: DEBUG :: SQL statement executed successfully\n",
      "2025-12-01 13:54:21,706 :: PID 20676 :: TID 29572 :: database._close_connection :: Line 44 :: DEBUG :: Closed connection to SQLite database\n"
     ]
    }
   ],
   "source": [
    "fs.write_parquet(interchange_df, target_layer, client_id, file_id, subdir=target_subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = merged_data.copy()\n",
    "rules = rules_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "jurisdiction_list = transactions[\"jurisdiction_assigned\"].unique()\n",
    "rules_to_evaluate = rules[rules[\"region_country_code\"].isin(jurisdiction_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[\"interchange_region_country_code\"] = \"\"\n",
    "transactions[\"interchange_intelica_id\"] = -1\n",
    "transactions[\"interchange_fee_descriptor\"] = \"\"\n",
    "transactions[\"interchange_fee_currency\"] = \"\"\n",
    "transactions[\"interchange_fee_variable\"] = 0.0\n",
    "transactions[\"interchange_fee_fixed\"] = 0.0\n",
    "transactions[\"interchange_fee_min\"] = 0.0\n",
    "transactions[\"interchange_fee_cap\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each rule definition.\n",
    "conditions_to_skip = [\n",
    "    \"region_country_code\",\n",
    "    \"valid_from\",\n",
    "    \"valid_until\",\n",
    "    \"intelica_id\",\n",
    "    \"fee_descriptor\",\n",
    "    \"fee_currency\",\n",
    "    \"fee_variable\",\n",
    "    \"fee_fixed\",\n",
    "    \"fee_min\",\n",
    "    \"fee_cap\",\n",
    "]\n",
    "update_columns = [\n",
    "    \"region_country_code\",\n",
    "    \"intelica_id\",\n",
    "    \"fee_descriptor\",\n",
    "    \"fee_currency\",\n",
    "    \"fee_variable\",\n",
    "    \"fee_fixed\",\n",
    "    \"fee_min\",\n",
    "    \"fee_cap\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['region_country_code',\n",
       " 'valid_from',\n",
       " 'valid_until',\n",
       " 'intelica_id',\n",
       " 'fee_descriptor',\n",
       " 'fee_currency',\n",
       " 'fee_variable',\n",
       " 'fee_fixed',\n",
       " 'fee_min',\n",
       " 'fee_cap']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditions_to_skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, rule in rules_to_evaluate.iterrows():\n",
    "        # Step 1: Filter unprocessed transactions and decide to break, skip or evaluate.\n",
    "        next_batch = transactions[\n",
    "            (transactions[\"interchange_intelica_id\"] == -1)\n",
    "            & (transactions[\"jurisdiction_assigned\"] == rule[\"region_country_code\"])\n",
    "        ]\n",
    "        if next_batch.empty:\n",
    "            continue\n",
    "        # Step 2: Iterate through each condition in the rule and apply its condition.\n",
    "        conditions = [\n",
    "            str(cond_name)\n",
    "            for cond_name in rule.index.to_list()\n",
    "            if cond_name not in conditions_to_skip and rule[cond_name] != \"\"\n",
    "        ]\n",
    "        for condition in conditions:\n",
    "            next_batch = _apply_condition(condition, rule[condition], next_batch, rates)\n",
    "            if next_batch.empty:\n",
    "                break\n",
    "        # Step 3: Update transaction table with batch results.\n",
    "        if not next_batch.empty:\n",
    "            for column in update_columns:\n",
    "                next_batch.loc[:, f\"interchange_{column}\"] = rule[column]\n",
    "            transactions.update(\n",
    "                next_batch[[f\"interchange_{c}\" for c in update_columns]]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_return = [f\"interchange_{c}\" for c in update_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_return = [\n",
    "    \"source_currency_code_alphabetic\",\n",
    "    \"source_amount\",\n",
    "] + columns_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions[columns_to_return]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
