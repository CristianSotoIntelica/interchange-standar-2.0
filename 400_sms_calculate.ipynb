{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VARIABLES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interchange.persistence.file import FileStorage\n",
    "from interchange.visa import transform, extract, clean, calculate, interchange, store\n",
    "\n",
    "layer = FileStorage.Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = \"SBSA\"\n",
    "file_id = \"B6781ADDCFE0CD800BFA2968A6ED2816\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_layer = layer.STAGING\n",
    "target_layer = layer.STAGING\n",
    "client_id = client_id\n",
    "file_id = file_id\n",
    "origin_subdir = \"300-SMS_CLN_MESSAGES\"\n",
    "target_subdir = \"400-SMS_CAL_MESSAGES\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "staging staging SBSA B6781ADDCFE0CD800BFA2968A6ED2816 300-SMS_CLN_MESSAGES 400-SMS_CAL_MESSAGES\n"
     ]
    }
   ],
   "source": [
    "print(origin_layer, target_layer, client_id, file_id, origin_subdir, target_subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from datetime import date\n",
    "from typing import Type\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from interchange.logs.logger import Logger\n",
    "from interchange.persistence.database import Database\n",
    "from interchange.persistence.file import FileStorage\n",
    "\n",
    "\n",
    "pd.set_option(\"future.no_silent_downcasting\", True)\n",
    "\n",
    "log = Logger(__name__)\n",
    "fs = FileStorage()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CalculatedField(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class that all calculated field objects must inherit from.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, client_data: pd.Series, file_data: pd.Series, ardef_data: pd.DataFrame\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.client = client_data\n",
    "        self.file = file_data\n",
    "        self.ardef = ardef_data\n",
    "\n",
    "    def _get_from_ardef(self, intervals: pd.Series, ardef_field: str) -> pd.Series:\n",
    "        \"\"\"\n",
    "        Get an ARDEF field's values corresponding to a series of account intervals.\n",
    "        \"\"\"\n",
    "        df = intervals.to_frame()\n",
    "        df = pd.merge(\n",
    "            df,\n",
    "            self.ardef[[\"account_interval\", ardef_field]],\n",
    "            on=\"account_interval\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        return df[ardef_field]\n",
    "\n",
    "    @abstractmethod\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        \"\"\"\n",
    "        This method will always get called to calculate a new field.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas.core.api import Series as Series\n",
    "\n",
    "\n",
    "class acquirer_bin(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"sms\":\n",
    "                return source[\"retrieval_reference_number\"].str.slice(0, 6)\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class ardef_country(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                return self._get_from_ardef(source[\"account_interval\"], \"ardef_country\")\n",
    "            case \"sms\":\n",
    "                return self._get_from_ardef(source[\"account_interval\"], \"ardef_country\")\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class authorization_code_valid(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                conditions = [\n",
    "                    (source[\"authorization_code\"].str[-1] == \"x\"),\n",
    "                    (\n",
    "                        source[\"authorization_code\"]\n",
    "                        .str[-5:]\n",
    "                        .isin([\" \", \"0000\", \"00000\", \"0000n\", \"0000p\", \"0000y\"])\n",
    "                    ),\n",
    "                ]\n",
    "                condition_values = [\"INVALID\", \"INVALID\"]\n",
    "                return pd.Series(\n",
    "                    np.select(conditions, condition_values, default=\"VALID\")\n",
    "                )\n",
    "            case \"sms\":\n",
    "                conditions = [\n",
    "                    (source[\"authorization_id_resp._code\"].str[-1] == \"x\"),\n",
    "                    (\n",
    "                        source[\"authorization_id_resp._code\"]\n",
    "                        .str[-5:]\n",
    "                        .isin([\" \", \"0000\", \"00000\", \"0000n\", \"0000p\", \"0000y\"])\n",
    "                    ),\n",
    "                ]\n",
    "                condition_values = [\"INVALID\", \"INVALID\"]\n",
    "                return pd.Series(\n",
    "                    np.select(conditions, condition_values, default=\"VALID\")\n",
    "                )\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class b2b_program_id(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                return self._get_from_ardef(\n",
    "                    source[\"account_interval\"], \"b2b_program_id\"\n",
    "                )\n",
    "            case \"sms\":\n",
    "                return self._get_from_ardef(\n",
    "                    source[\"account_interval\"], \"b2b_program_id\"\n",
    "                )\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class business_application_id(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                df = source[\n",
    "                    [\n",
    "                        \"business_application_id_fl\",\n",
    "                        \"business_application_id_cr\",\n",
    "                        \"business_application_id_ft\",\n",
    "                    ]\n",
    "                ]\n",
    "                df = df.apply(lambda x: x.str.strip())\n",
    "                df = df.replace(\"\", np.nan)\n",
    "                return df.bfill(axis=1).iloc[:, 0]\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class business_format_code(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                df = source[\n",
    "                    [\n",
    "                        \"business_format_code_cr\",\n",
    "                        \"business_format_code_fl\",\n",
    "                        \"business_format_code_ft\",\n",
    "                        \"business_format_code_df\",\n",
    "                        \"business_format_code_pd\",\n",
    "                        \"business_format_code_sd\",\n",
    "                        \"business_format_code_sp\",\n",
    "                    ]\n",
    "                ]\n",
    "                df = df.apply(lambda x: x.str.strip())\n",
    "                df = df.replace(\"\", np.nan)\n",
    "                return df.bfill(axis=1).iloc[:, 0]\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class business_mode(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                conditions = [\n",
    "                    (\n",
    "                        source[\"draft_code\"].isin([\"05\", \"25\", \"06\", \"26\", \"07\", \"27\"])\n",
    "                        & (self.file[\"file_type\"] == \"OUT\")\n",
    "                    ),\n",
    "                    (\n",
    "                        source[\"draft_code\"].isin([\"15\", \"35\", \"16\", \"36\", \"17\", \"37\"])\n",
    "                        & (self.file[\"file_type\"] == \"OUT\")\n",
    "                    ),\n",
    "                    (\n",
    "                        source[\"draft_code\"].isin([\"05\", \"25\", \"06\", \"26\", \"07\", \"27\"])\n",
    "                        & (self.file[\"file_type\"] == \"IN\")\n",
    "                    ),\n",
    "                    (\n",
    "                        source[\"draft_code\"].isin([\"15\", \"35\", \"16\", \"36\", \"17\", \"37\"])\n",
    "                        & (self.file[\"file_type\"] == \"IN\")\n",
    "                    ),\n",
    "                ]\n",
    "                condition_values = [\n",
    "                    \"Acquiring\",\n",
    "                    \"Issuing\",\n",
    "                    \"Issuing\",\n",
    "                    \"Acquiring\",\n",
    "                ]  # Acquiring or Issuing\n",
    "                return pd.Series(np.select(conditions, condition_values, default=\"\"))\n",
    "            case \"sms\":\n",
    "                conditions = [\n",
    "                    (source[\"issuer_acquirer_indicator\"] == \"A\"),\n",
    "                    (source[\"issuer_acquirer_indicator\"] == \"I\"),\n",
    "                ]\n",
    "                condition_values = [\n",
    "                    \"Acquiring\",\n",
    "                    \"Issuing\",\n",
    "                ]\n",
    "                return pd.Series(np.select(conditions, condition_values, default=\"\"))\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class business_transaction_type(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                conditions = [\n",
    "                    (\n",
    "                        source[\"draft_code\"].isin([\"05\", \"15\", \"25\", \"35\"])\n",
    "                        & ~source[\"merchant_category_code\"].isin([4829, 6051, 7995])\n",
    "                    ),\n",
    "                    (\n",
    "                        source[\"draft_code\"].isin([\"05\", \"15\", \"25\", \"35\"])\n",
    "                        & source[\"merchant_category_code\"].isin([4829, 6051, 7995])\n",
    "                    ),\n",
    "                    (\n",
    "                        source[\"draft_code\"].isin([\"06\", \"16\", \"26\", \"36\"])\n",
    "                        & (source[\"usage_code\"] == 1)\n",
    "                    ),\n",
    "                    (\n",
    "                        source[\"draft_code\"].isin([\"06\", \"16\", \"26\", \"36\"])\n",
    "                        & (source[\"usage_code\"] == 1)\n",
    "                        & source[\n",
    "                            \"special_condition_indicator_merchant_draft_indicator\"\n",
    "                        ].isin([\"7\", \"8\"])\n",
    "                    ),\n",
    "                    (\n",
    "                        source[\"draft_code\"].isin([\"06\", \"16\", \"26\", \"36\"])\n",
    "                        & (source[\"usage_code\"] == 1)\n",
    "                        & (source[\"draft_code_qualifier_0\"] == 2)\n",
    "                    ),\n",
    "                    (\n",
    "                        source[\"draft_code\"].isin([\"07\", \"17\", \"27\", \"37\"])\n",
    "                        & (source[\"merchant_category_code\"] == 6010)\n",
    "                    ),\n",
    "                    (\n",
    "                        source[\"draft_code\"].isin([\"07\", \"17\", \"27\", \"37\"])\n",
    "                        & (source[\"merchant_category_code\"] == 6011)\n",
    "                    ),\n",
    "                ]\n",
    "                condition_values = [1, 3, 19, 20, 25, 21, 22]\n",
    "                return pd.Series(np.select(conditions, condition_values, default=255))\n",
    "            case \"sms\":\n",
    "                rmt = source[\"request_message_type\"]\n",
    "                rc = source[\"response_code\"]\n",
    "                pc = source[\"processing_code\"].str[:2]\n",
    "                pos = source[\"pos_condition_code\"]\n",
    "                mcc = source[\"merchant's_type\"]\n",
    "\n",
    "                # Condiciones del primer bloque: response_code = '00'\n",
    "                cond_success = rmt.isin([\"0200\", \"0220\", \"0400\", \"0420\"]) & (rc == \"00\")\n",
    "\n",
    "                # Segundo bloque: response_code != '00'\n",
    "                cond_decline = rmt.isin([\"0200\", \"0220\", \"0400\", \"0420\"]) & (rc != \"00\")\n",
    "\n",
    "                conditions = [\n",
    "                    (\n",
    "                        cond_success\n",
    "                        & (pc == \"00\")\n",
    "                        & ~pos.isin([\"13\", \"51\"])\n",
    "                        & ~mcc.isin([4815, 6010, 6011])\n",
    "                    ),\n",
    "                    (\n",
    "                        cond_success\n",
    "                        & (pc == \"01\")\n",
    "                        & ~pos.isin([\"13\", \"51\"])\n",
    "                        & (mcc == 6010)\n",
    "                    ),\n",
    "                    (\n",
    "                        cond_success\n",
    "                        & (pc == \"01\")\n",
    "                        & ~pos.isin([\"13\", \"51\"])\n",
    "                        & (mcc == 6011)\n",
    "                    ),\n",
    "                    (\n",
    "                        cond_success\n",
    "                        & (pc == \"10\")\n",
    "                        & ~pos.isin([\"13\", \"51\"])\n",
    "                        & ~mcc.isin([4815, 6010, 6011])\n",
    "                    ),\n",
    "                    (\n",
    "                        cond_success\n",
    "                        & (pc == \"11\")\n",
    "                        & ~pos.isin([\"13\", \"51\"])\n",
    "                        & ~mcc.isin([4815, 6010, 6011])\n",
    "                    ),\n",
    "                    (\n",
    "                        cond_success\n",
    "                        & (pc == \"19\")\n",
    "                        & ~pos.isin([\"13\", \"51\"])\n",
    "                        & ~mcc.isin([4815, 6010, 6011])\n",
    "                    ),\n",
    "                    (\n",
    "                        cond_success\n",
    "                        & (pc == \"20\")\n",
    "                        & ~pos.isin([\"13\", \"51\"])\n",
    "                        & ~mcc.isin([4815, 6010, 6011])\n",
    "                    ),\n",
    "                    (\n",
    "                        cond_success\n",
    "                        & (pc == \"22\")\n",
    "                        & pos.isin([\"13\"])\n",
    "                        & ~mcc.isin([4815, 6010, 6011])\n",
    "                    ),\n",
    "                    (\n",
    "                        cond_success\n",
    "                        & (pc == \"26\")\n",
    "                        & ~pos.isin([\"13\", \"51\"])\n",
    "                        & ~mcc.isin([4815, 6010, 6011])\n",
    "                    ),\n",
    "                    (\n",
    "                        cond_success\n",
    "                        & (pc == \"29\")\n",
    "                        & ~pos.isin([\"13\", \"51\"])\n",
    "                        & ~mcc.isin([4815, 6010, 6011])\n",
    "                    ),\n",
    "                    (\n",
    "                        cond_success\n",
    "                        & (pc == \"30\")\n",
    "                        & ~pos.isin([\"13\", \"51\"])\n",
    "                        & (mcc == 6011)\n",
    "                    ),\n",
    "                    (\n",
    "                        cond_success\n",
    "                        & (pc == \"40\")\n",
    "                        & ~pos.isin([\"13\", \"51\"])\n",
    "                        & (mcc == 6011)\n",
    "                    ),\n",
    "                    (\n",
    "                        cond_success\n",
    "                        & (pc == \"50\")\n",
    "                        & ~pos.isin([\"13\", \"51\"])\n",
    "                        & ~mcc.isin([4815, 6010, 6011])\n",
    "                    ),\n",
    "                    (cond_decline & (mcc != 6011)),\n",
    "                    (cond_decline & (mcc == 6011)),\n",
    "                ]\n",
    "\n",
    "                condition_values = [\n",
    "                    1,\n",
    "                    21,\n",
    "                    22,\n",
    "                    30,\n",
    "                    3,\n",
    "                    115,\n",
    "                    19,\n",
    "                    20,\n",
    "                    25,\n",
    "                    200,\n",
    "                    247,\n",
    "                    250,\n",
    "                    27,\n",
    "                    236,\n",
    "                    249,\n",
    "                ]\n",
    "\n",
    "                return pd.Series(\n",
    "                    np.select(conditions, condition_values, default=np.nan),\n",
    "                    index=source.index,\n",
    "                )\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class fast_funds(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                return self._get_from_ardef(source[\"account_interval\"], \"fast_funds\")\n",
    "            case \"sms\":\n",
    "                return self._get_from_ardef(source[\"account_interval\"], \"fast_funds\")\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class funding_source(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                return self._get_from_ardef(\n",
    "                    source[\"account_interval\"], \"account_funding_source\"\n",
    "                )\n",
    "            case \"sms\":\n",
    "                return self._get_from_ardef(\n",
    "                    source[\"account_interval\"], \"account_funding_source\"\n",
    "                )\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class issuer_bin_8(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                return source[\"account_number\"].str.replace(\"*\", \"0\").str.slice(0, 8)\n",
    "            case \"sms\":\n",
    "                return source[\"card_number\"].str.replace(\"*\", \"0\").str.slice(0, 8)\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class issuer_country(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                return self._get_from_ardef(source[\"account_interval\"], \"country\")\n",
    "            case \"sms\":\n",
    "                return self._get_from_ardef(source[\"account_interval\"], \"country\")\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class issuer_region(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                return self._get_from_ardef(source[\"account_interval\"], \"region\")\n",
    "            case \"sms\":\n",
    "                return self._get_from_ardef(source[\"account_interval\"], \"region\")\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class jurisdiction(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        db = Database()\n",
    "        country = db.read_records(\n",
    "            table_name=\"country\",\n",
    "            fields=[\"country_code\", \"visa_region_code\"],\n",
    "        ).rename(\n",
    "            columns={\n",
    "                \"country_code\": \"merchant_country_code\",\n",
    "                \"visa_region_code\": \"merchant_region_code\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        country_ardef = db.read_records(\n",
    "            table_name=\"country\",\n",
    "            fields=[\"country_code\", \"visa_region_code\"],\n",
    "        ).rename(\n",
    "            columns={\n",
    "                \"country_code\": \"ardef_country\",\n",
    "                \"visa_region_code\": \"ardef_region\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        ar_countries = self._get_from_ardef(source[\"account_interval\"], \"ardef_country\")\n",
    "        ar_countries.name = \"ardef_country\"\n",
    "        issuing_bins_6 = str(self.client[\"issuing_bins_6_digits\"]).split(\",\")\n",
    "        issuing_bins_8 = str(self.client[\"issuing_bins_8_digits\"]).split(\",\")\n",
    "        acquiring_bins = str(self.client[\"acquiring_bins\"]).split(\",\")\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                source = pd.merge(\n",
    "                    source,\n",
    "                    country,\n",
    "                    how=\"left\",\n",
    "                    on=\"merchant_country_code\",\n",
    "                )\n",
    "                source = source.join(ar_countries, how=\"left\")\n",
    "                source = source.merge(\n",
    "                    country_ardef,\n",
    "                    how=\"left\",\n",
    "                    on=\"ardef_country\",\n",
    "                )\n",
    "                conditions = [\n",
    "                    (\n",
    "                        (source[\"merchant_country_code\"] == source[\"ardef_country\"])\n",
    "                        & (self.file[\"file_type\"] == \"OUT\")\n",
    "                        & (\n",
    "                            (source[\"collection_only_flag\"] == \"C\")\n",
    "                            | (\n",
    "                                source[\"account_number\"]\n",
    "                                .str.replace(\"*\", \"0\")\n",
    "                                .str.slice(0, 6)\n",
    "                                .isin(issuing_bins_6)\n",
    "                            )\n",
    "                            | (\n",
    "                                source[\"account_number\"]\n",
    "                                .str.replace(\"*\", \"0\")\n",
    "                                .str.slice(0, 8)\n",
    "                                .isin(issuing_bins_8)\n",
    "                            )\n",
    "                        )\n",
    "                    ),\n",
    "                    (\n",
    "                        (source[\"merchant_country_code\"] == source[\"ardef_country\"])\n",
    "                        & (self.file[\"file_type\"] == \"IN\")\n",
    "                        & (\n",
    "                            (source[\"collection_only_flag\"] == \"C\")\n",
    "                            | (\n",
    "                                source[\"account_reference_number_acquiring_identifier\"]\n",
    "                                .astype(str)\n",
    "                                .str.zfill(6)\n",
    "                                .isin(acquiring_bins)\n",
    "                            )\n",
    "                        )\n",
    "                    ),\n",
    "                    (source[\"merchant_country_code\"] == source[\"ardef_country\"]),\n",
    "                    (\n",
    "                        (source[\"merchant_country_code\"] != source[\"ardef_country\"])\n",
    "                        & (source[\"merchant_region_code\"] == source[\"ardef_region\"])\n",
    "                    ),\n",
    "                    (\n",
    "                        (source[\"merchant_country_code\"] != source[\"ardef_country\"])\n",
    "                        & (source[\"merchant_region_code\"] != source[\"ardef_region\"])\n",
    "                    ),\n",
    "                ]\n",
    "                condition_values = [\n",
    "                    \"on-us\",\n",
    "                    \"on-us\",\n",
    "                    \"off-us\",\n",
    "                    \"intraregional\",\n",
    "                    \"interregional\",\n",
    "                ]\n",
    "                return pd.Series(np.select(conditions, condition_values, default=\"\"))\n",
    "            case \"sms\":\n",
    "                source = pd.merge(\n",
    "                    source,\n",
    "                    country,\n",
    "                    how=\"left\",\n",
    "                    left_on=\"card_acceptor_country\",\n",
    "                    right_on=\"merchant_country_code\",\n",
    "                )\n",
    "                source = source.join(ar_countries, how=\"left\")\n",
    "                source = source.merge(\n",
    "                    country_ardef,\n",
    "                    how=\"left\",\n",
    "                    on=\"ardef_country\",\n",
    "                )\n",
    "                conditions = [\n",
    "                    (\n",
    "                        (source[\"merchant_country_code\"] == source[\"ardef_country\"])\n",
    "                        & (source[\"issuer_acquirer_indicator\"] == \"A\")\n",
    "                        & (\n",
    "                            (\n",
    "                                source[\"card_number\"]\n",
    "                                .str.replace(\"*\", \"0\")\n",
    "                                .str.slice(0, 6)\n",
    "                                .isin(issuing_bins_6)\n",
    "                            )\n",
    "                            | (\n",
    "                                source[\"card_number\"]\n",
    "                                .str.replace(\"*\", \"0\")\n",
    "                                .str.slice(0, 8)\n",
    "                                .isin(issuing_bins_8)\n",
    "                            )\n",
    "                        )\n",
    "                    ),\n",
    "                    (\n",
    "                        (source[\"merchant_country_code\"] == source[\"ardef_country\"])\n",
    "                        & (source[\"issuer_acquirer_indicator\"] == \"I\")\n",
    "                        & (\n",
    "                            source[\"acquiring_institution_id_1\"]\n",
    "                            .astype(str)\n",
    "                            .str.zfill(6)\n",
    "                            .isin(acquiring_bins)\n",
    "                        )\n",
    "                    ),\n",
    "                    (source[\"merchant_country_code\"] == source[\"ardef_country\"]),\n",
    "                    (\n",
    "                        (source[\"merchant_country_code\"] != source[\"ardef_country\"])\n",
    "                        & (source[\"merchant_region_code\"] == source[\"ardef_region\"])\n",
    "                    ),\n",
    "                    (\n",
    "                        (source[\"merchant_country_code\"] != source[\"ardef_country\"])\n",
    "                        & (source[\"merchant_region_code\"] != source[\"ardef_region\"])\n",
    "                    ),\n",
    "                ]\n",
    "                condition_values = [\n",
    "                    \"on-us\",\n",
    "                    \"on-us\",\n",
    "                    \"off-us\",\n",
    "                    \"intraregional\",\n",
    "                    \"interregional\",\n",
    "                ]\n",
    "                return pd.Series(np.select(conditions, condition_values, default=\"\"))\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class jurisdiction_assigned(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        db = Database()\n",
    "        country = db.read_records(\n",
    "            table_name=\"country\",\n",
    "            fields=[\"country_code\", \"visa_region_code\"],\n",
    "        ).rename(\n",
    "            columns={\n",
    "                \"country_code\": \"merchant_country_code\",\n",
    "                \"visa_region_code\": \"merchant_region_code\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "        country_ardef = db.read_records(\n",
    "            table_name=\"country\",\n",
    "            fields=[\"country_code\", \"visa_region_code\"],\n",
    "        ).rename(\n",
    "            columns={\n",
    "                \"country_code\": \"ardef_country\",\n",
    "                \"visa_region_code\": \"ardef_region\",\n",
    "            }\n",
    "        )\n",
    "        ar_countries = self._get_from_ardef(source[\"account_interval\"], \"ardef_country\")\n",
    "        ar_countries.name = \"ardef_country\"\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                source = pd.merge(\n",
    "                    source,\n",
    "                    country,\n",
    "                    how=\"left\",\n",
    "                    on=\"merchant_country_code\",\n",
    "                )\n",
    "                source = source.join(ar_countries, how=\"left\")\n",
    "                source = source.merge(\n",
    "                    country_ardef,\n",
    "                    how=\"left\",\n",
    "                    on=\"ardef_country\",\n",
    "                )\n",
    "                source[\"jurisdiction_assigned\"] = \"\"  # Initialize field\n",
    "                source.loc[\n",
    "                    (source[\"merchant_country_code\"] == source[\"ardef_country\"]),\n",
    "                    \"jurisdiction_assigned\",\n",
    "                ] = source[\"merchant_country_code\"]\n",
    "                source.loc[\n",
    "                    (\n",
    "                        (source[\"merchant_country_code\"] != source[\"ardef_country\"])\n",
    "                        & (source[\"merchant_region_code\"] == source[\"ardef_region\"])\n",
    "                    ),\n",
    "                    \"jurisdiction_assigned\",\n",
    "                ] = source[\"ardef_region\"]\n",
    "                source.loc[\n",
    "                    (\n",
    "                        (source[\"merchant_country_code\"] != source[\"ardef_country\"])\n",
    "                        & (source[\"merchant_region_code\"] != source[\"ardef_region\"])\n",
    "                    ),\n",
    "                    \"jurisdiction_assigned\",\n",
    "                ] = \"9\"  # Interregional\n",
    "                return source[\"jurisdiction_assigned\"]\n",
    "            case \"sms\":\n",
    "                source = pd.merge(\n",
    "                    source,\n",
    "                    country,\n",
    "                    how=\"left\",\n",
    "                    left_on=\"card_acceptor_country\",\n",
    "                    right_on=\"merchant_country_code\",\n",
    "                )\n",
    "                source = source.join(ar_countries, how=\"left\")\n",
    "                source = source.merge(\n",
    "                    country_ardef,\n",
    "                    how=\"left\",\n",
    "                    on=\"ardef_country\",\n",
    "                )\n",
    "                source[\"jurisdiction_assigned\"] = \"\"  # Initialize field\n",
    "                source.loc[\n",
    "                    (source[\"merchant_country_code\"] == source[\"ardef_country\"]),\n",
    "                    \"jurisdiction_assigned\",\n",
    "                ] = source[\"merchant_country_code\"]\n",
    "                source.loc[\n",
    "                    (\n",
    "                        (source[\"merchant_country_code\"] != source[\"ardef_country\"])\n",
    "                        & (source[\"merchant_region_code\"] == source[\"ardef_region\"])\n",
    "                    ),\n",
    "                    \"jurisdiction_assigned\",\n",
    "                ] = source[\"ardef_region\"]\n",
    "                source.loc[\n",
    "                    (\n",
    "                        (source[\"merchant_country_code\"] != source[\"ardef_country\"])\n",
    "                        & (source[\"merchant_region_code\"] != source[\"ardef_region\"])\n",
    "                    ),\n",
    "                    \"jurisdiction_assigned\",\n",
    "                ] = \"9\"  # Interregional\n",
    "                return source[\"jurisdiction_assigned\"]\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class jurisdiction_country(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                return source[\"merchant_country_code\"]\n",
    "            case \"sms\":\n",
    "                return source[\"card_acceptor_country\"]\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class jurisdiction_region(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        db = Database()\n",
    "        country = db.read_records(\n",
    "            table_name=\"country\",\n",
    "            fields=[\"country_code\", \"visa_region_code\"],\n",
    "        )\n",
    "        country.rename(\n",
    "            columns={\n",
    "                \"country_code\": \"merchant_country_code\",\n",
    "                \"visa_region_code\": \"merchant_region_code\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                source = pd.merge(\n",
    "                    source,\n",
    "                    country,\n",
    "                    how=\"left\",\n",
    "                    on=\"merchant_country_code\",\n",
    "                )\n",
    "                return source[\"merchant_region_code\"]\n",
    "            case \"sms\":\n",
    "                source = pd.merge(\n",
    "                    source,\n",
    "                    country,\n",
    "                    how=\"left\",\n",
    "                    left_on=\"card_acceptor_country\",\n",
    "                    right_on=\"merchant_country_code\",\n",
    "                )\n",
    "                return source[\"merchant_region_code\"]\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class message_reason_code(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                df = source[\n",
    "                    [\n",
    "                        \"message_reason_code_df\",\n",
    "                        \"message_reason_code_sd\",\n",
    "                        \"message_reason_code_sp\",\n",
    "                    ]\n",
    "                ]\n",
    "                df = df.apply(lambda x: x.str.strip())\n",
    "                df = df.replace(\"\", np.nan)\n",
    "                return df.bfill(axis=1).iloc[:, 0]\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class network_identification_code(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                df = source[\n",
    "                    [\n",
    "                        \"network_identification_code_df\",\n",
    "                        \"network_identification_code_sd\",\n",
    "                        \"network_identification_code_sp\",\n",
    "                    ]\n",
    "                ]\n",
    "                df = df.apply(lambda x: x.str.strip())\n",
    "                df = df.replace(\"\", np.nan)\n",
    "                return df.bfill(axis=1).iloc[:, 0]\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class nnss_indicator(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                return self._get_from_ardef(\n",
    "                    source[\"account_interval\"], \"nnss_indicator\"\n",
    "                )\n",
    "            case \"sms\":\n",
    "                return self._get_from_ardef(\n",
    "                    source[\"account_interval\"], \"nnss_indicator\"\n",
    "                )\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class processing_code_transaction_type(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"sms\":\n",
    "                return source[\"processing_code\"].str.slice(0, 2)\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class product_id(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                return self._get_from_ardef(source[\"account_interval\"], \"product_id\")\n",
    "            case \"sms\":\n",
    "                return self._get_from_ardef(source[\"account_interval\"], \"product_id\")\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class product_subtype(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                return self._get_from_ardef(\n",
    "                    source[\"account_interval\"], \"product_subtype\"\n",
    "                )\n",
    "            case \"sms\":\n",
    "                return self._get_from_ardef(\n",
    "                    source[\"account_interval\"], \"product_subtype\"\n",
    "                )\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class reversal_indicator(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                conditions = [\n",
    "                    (source[\"draft_code\"].isin([\"25\", \"26\", \"27\", \"35\", \"36\", \"37\"]))\n",
    "                ]\n",
    "                condition_values = [1]\n",
    "                return pd.Series(np.select(conditions, condition_values, default=0))\n",
    "            case \"sms\":\n",
    "                conditions = [\n",
    "                    (\n",
    "                        source[\"request_message_type\"].isin([\"0200\", \"0220\"])\n",
    "                        & source[\"response_code\"].isin([\"00\"])\n",
    "                    ),\n",
    "                    (\n",
    "                        source[\"request_message_type\"].isin([\"0400\", \"0420\"])\n",
    "                        & source[\"response_code\"].isin([\"00\"])\n",
    "                    ),\n",
    "                ]\n",
    "                condition_values = [0, 1]\n",
    "                return pd.Series(np.select(conditions, condition_values, default=0))\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class source_amount(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"sms\":\n",
    "                return source[\"draft_amount\"]\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class source_currency_code_alphabetic(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        db = Database()\n",
    "        country = db.read_records(\n",
    "            table_name=\"currency\",\n",
    "            fields=[\"currency_numeric_code\", \"currency_alphabetic_code\"],\n",
    "        )\n",
    "        country.rename(\n",
    "            columns={\n",
    "                \"currency_numeric_code\": \"source_currency_code\",\n",
    "                \"currency_alphabetic_code\": \"source_currency_code_alphabetic\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                source = pd.merge(\n",
    "                    source,\n",
    "                    country,\n",
    "                    how=\"left\",\n",
    "                    on=\"source_currency_code\",\n",
    "                )\n",
    "                return source[\"source_currency_code_alphabetic\"]\n",
    "            case \"sms\":\n",
    "                source = pd.merge(\n",
    "                    source,\n",
    "                    country,\n",
    "                    how=\"left\",\n",
    "                    left_on=\"draft_currency_code\",\n",
    "                    right_on=\"source_currency_code\",\n",
    "                )\n",
    "                return source[\"source_currency_code_alphabetic\"]\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class surcharge_amount(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                df = source[\n",
    "                    [\n",
    "                        \"surcharge_amount_df\",\n",
    "                        \"surcharge_amount_sd\",\n",
    "                        \"surcharge_amount_sp\",\n",
    "                    ]\n",
    "                ]\n",
    "                return df.max(axis=1)\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class technology_indicator(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                return self._get_from_ardef(\n",
    "                    source[\"account_interval\"], \"technology_indicator\"\n",
    "                )\n",
    "            case \"sms\":\n",
    "                return self._get_from_ardef(\n",
    "                    source[\"account_interval\"], \"technology_indicator\"\n",
    "                )\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class timeliness(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                return (\n",
    "                    source[\"central_processing_date\"] - source[\"purchase_date\"]\n",
    "                ).dt.days\n",
    "            case \"sms\":\n",
    "                return (\n",
    "                    source[\"settlement_date_sms\"] - source[\"local_draft_date\"]\n",
    "                ).dt.days\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class transaction_code_sms(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        db = Database()\n",
    "        transaction_type = db.read_records(\n",
    "            table_name=\"visa_transaction_type\",\n",
    "            fields=[\"business_transaction_type_id\", \"transaction_type_id\"],\n",
    "        )\n",
    "\n",
    "        btt_series = business_transaction_type(\n",
    "            self.client,\n",
    "            self.file,\n",
    "            self.ardef,\n",
    "        ).calculate(source, type_record)\n",
    "        btt_series.name = \"business_transaction_type_id\"\n",
    "\n",
    "        reversal_series = reversal_indicator(\n",
    "            self.client,\n",
    "            self.file,\n",
    "            self.ardef,\n",
    "        ).calculate(source, type_record)\n",
    "        reversal_series.name = \"reversal_indicator\"\n",
    "\n",
    "        df = pd.DataFrame(\n",
    "            {\n",
    "                \"business_transaction_type_id\": btt_series,\n",
    "                \"reversal_indicator\": reversal_series,\n",
    "            }\n",
    "        )\n",
    "        df[\"business_transaction_type_id\"] = (\n",
    "            df[\"business_transaction_type_id\"]\n",
    "            .astype(float)  # asegura que todos sean nÃºmeros\n",
    "            .astype(\"Int64\")  # Pandas Int64 acepta NaN\n",
    "            .astype(str)  # finalmente a string para merge con transaction_type\n",
    "        )\n",
    "        df = df.merge(\n",
    "            transaction_type[[\"business_transaction_type_id\", \"transaction_type_id\"]],\n",
    "            on=\"business_transaction_type_id\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "        match type_record:\n",
    "            case \"sms\":\n",
    "                conditions = [\n",
    "                    (df[\"transaction_type_id\"] == \"PUR\")\n",
    "                    & (df[\"reversal_indicator\"] == 0),\n",
    "                    (df[\"transaction_type_id\"] == \"CRD\")\n",
    "                    & (df[\"reversal_indicator\"] == 0),\n",
    "                    (df[\"transaction_type_id\"] == \"CSH\")\n",
    "                    & (df[\"reversal_indicator\"] == 0),\n",
    "                    (df[\"transaction_type_id\"] == \"PUR\")\n",
    "                    & (df[\"reversal_indicator\"] == 1),\n",
    "                    (df[\"transaction_type_id\"] == \"CRD\")\n",
    "                    & (df[\"reversal_indicator\"] == 1),\n",
    "                    (df[\"transaction_type_id\"] == \"CSH\")\n",
    "                    & (df[\"reversal_indicator\"] == 1),\n",
    "                ]\n",
    "\n",
    "                condition_values = [\"05\", \"06\", \"07\", \"25\", \"26\", \"27\"]\n",
    "                return pd.Series(\n",
    "                    np.select(conditions, condition_values, default=\"\"),\n",
    "                    index=source.index,\n",
    "                )\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class travel_indicator(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                return self._get_from_ardef(\n",
    "                    source[\"account_interval\"], \"travel_indicator\"\n",
    "                )\n",
    "            case \"sms\":\n",
    "                return self._get_from_ardef(\n",
    "                    source[\"account_interval\"], \"travel_indicator\"\n",
    "                )\n",
    "            case _:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "class type_of_purchase(CalculatedField):\n",
    "    def calculate(self, source: pd.DataFrame, type_record: str) -> pd.Series:\n",
    "        match type_record:\n",
    "            case \"draft\":\n",
    "                df = source[\n",
    "                    [\n",
    "                        \"type_of_purchase_fl\",\n",
    "                        \"type_of_purchase_ft\",\n",
    "                    ]\n",
    "                ]\n",
    "                df = df.apply(lambda x: x.str.strip())\n",
    "                df = df.replace(\"\", np.nan)\n",
    "                return df.bfill(axis=1).iloc[:, 0]\n",
    "            case _:\n",
    "                raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCIONES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_client_data(client_id: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Get key metadata associated to a client.\n",
    "    \"\"\"\n",
    "    db = Database()\n",
    "    fd = db.read_records(\n",
    "        table_name=\"client\",\n",
    "        fields=[\n",
    "            \"local_currency_code\",\n",
    "            \"settlement_currency_code\",\n",
    "            \"report_currency_code\",\n",
    "            \"issuing_bins_6_digits\",\n",
    "            \"issuing_bins_8_digits\",\n",
    "            \"acquiring_bins\",\n",
    "            \"customer_country\",\n",
    "        ],\n",
    "        where={\"client_id\": client_id},\n",
    "    )\n",
    "    return fd.iloc[0]\n",
    "\n",
    "\n",
    "def _get_file_data(client_id: str, file_id: str) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Get key metadata associated to an interchange file.\n",
    "    \"\"\"\n",
    "    db = Database()\n",
    "    fd = db.read_records(\n",
    "        table_name=\"file_control\",\n",
    "        fields=[\n",
    "            \"brand_id\",\n",
    "            \"file_type\",\n",
    "            \"file_processing_date\",\n",
    "        ],\n",
    "        where={\"client_id\": client_id, \"file_id\": file_id},\n",
    "    )\n",
    "    fd[\"file_processing_date\"] = pd.to_datetime(\n",
    "        fd[\"file_processing_date\"], format=\"%Y-%m-%d\"\n",
    "    ).dt.date\n",
    "    return fd.iloc[0]\n",
    "\n",
    "\n",
    "def _get_visa_ardef(file_date: date) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a dataframe of Visa ARDEF records valid for the file_id's date.\n",
    "    \"\"\"\n",
    "    db = Database()\n",
    "    fd = db.read_records(\n",
    "        table_name=\"visa_ardef\",\n",
    "        fields=[\n",
    "            \"low_key_for_range\",\n",
    "            \"table_key\",\n",
    "            \"effective_date\",\n",
    "            \"valid_until\",\n",
    "            \"account_funding_source\",\n",
    "            \"ardef_country\",\n",
    "            \"ardef_region\",\n",
    "            \"b2b_program_id\",\n",
    "            \"country\",\n",
    "            \"fast_funds\",\n",
    "            \"nnss_indicator\",\n",
    "            \"product_id\",\n",
    "            \"product_subtype\",\n",
    "            \"region\",\n",
    "            \"technology_indicator\",\n",
    "            \"travel_indicator\",\n",
    "        ],\n",
    "        where={\"delete_indicator\": \" \"},\n",
    "    )\n",
    "    # Clean integer fields.\n",
    "    int_cols = [\"low_key_for_range\", \"table_key\"]\n",
    "    fd[int_cols] = fd[int_cols].apply(\n",
    "        pd.to_numeric, downcast=\"integer\", errors=\"coerce\"\n",
    "    )\n",
    "    # Clean date fields and default empty \"valid_until\" to file's date.\n",
    "    date_cols = [\"effective_date\", \"valid_until\"]\n",
    "    for col in date_cols:\n",
    "        fd[col] = pd.to_datetime(fd[col], format=\"%Y-%m-%d\", errors=\"coerce\").dt.date\n",
    "    fd[\"valid_until\"] = fd[\"valid_until\"].fillna(file_date)\n",
    "    # Filter out ranges that are not valid for the file's date.\n",
    "    fd = fd[(file_date >= fd[\"effective_date\"]) & (file_date <= fd[\"valid_until\"])]\n",
    "    # Remove duplicate keys and ranges that overlap with a previous range.\n",
    "    fd = fd.sort_values(\n",
    "        [\"table_key\", \"effective_date\", \"low_key_for_range\"],\n",
    "        ascending=[True, False, True],\n",
    "    )\n",
    "    fd = fd.drop_duplicates(subset=\"table_key\", keep=\"first\")\n",
    "    fd = fd.drop_duplicates(subset=\"low_key_for_range\", keep=\"first\")\n",
    "    fd[\"previous_table_key\"] = fd[\"table_key\"].shift(1)\n",
    "    fd[\"overlap\"] = fd[\"low_key_for_range\"] <= fd[\"previous_table_key\"]\n",
    "    fd = fd[~fd[\"overlap\"]].drop(columns=[\"previous_table_key\", \"overlap\"])\n",
    "    # Add an interval column to facilitate merge with transactions.\n",
    "    fd[\"account_interval\"] = pd.IntervalIndex.from_tuples(\n",
    "        list(zip(fd[\"low_key_for_range\"], fd[\"table_key\"])), closed=\"both\"\n",
    "    )\n",
    "    return fd.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROCESOS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 13:29:07,488 :: PID 38128 :: TID 33836 :: database._create_connection :: Line 33 :: DEBUG :: Connected to SQLite database\n",
      "2025-12-01 13:29:07,490 :: PID 38128 :: TID 33836 :: database.read_records :: Line 138 :: DEBUG :: Attempting to execute SELECT SQL statement\n",
      "2025-12-01 13:29:07,492 :: PID 38128 :: TID 33836 :: database._execute :: Line 57 :: DEBUG :: SQL statement executed successfully\n",
      "2025-12-01 13:29:07,493 :: PID 38128 :: TID 33836 :: database._close_connection :: Line 44 :: DEBUG :: Closed connection to SQLite database\n"
     ]
    }
   ],
   "source": [
    "data = fs.read_parquet(\n",
    "    origin_layer,\n",
    "    client_id,\n",
    "    file_id,\n",
    "    subdir=origin_subdir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 13:29:07,661 :: PID 38128 :: TID 33836 :: database._create_connection :: Line 33 :: DEBUG :: Connected to SQLite database\n",
      "2025-12-01 13:29:07,663 :: PID 38128 :: TID 33836 :: database.read_records :: Line 138 :: DEBUG :: Attempting to execute SELECT SQL statement\n",
      "2025-12-01 13:29:07,663 :: PID 38128 :: TID 33836 :: database._execute :: Line 57 :: DEBUG :: SQL statement executed successfully\n",
      "2025-12-01 13:29:07,663 :: PID 38128 :: TID 33836 :: database._close_connection :: Line 44 :: DEBUG :: Closed connection to SQLite database\n",
      "2025-12-01 13:29:07,673 :: PID 38128 :: TID 33836 :: database._create_connection :: Line 33 :: DEBUG :: Connected to SQLite database\n",
      "2025-12-01 13:29:07,674 :: PID 38128 :: TID 33836 :: database.read_records :: Line 138 :: DEBUG :: Attempting to execute SELECT SQL statement\n",
      "2025-12-01 13:29:07,676 :: PID 38128 :: TID 33836 :: database._execute :: Line 57 :: DEBUG :: SQL statement executed successfully\n",
      "2025-12-01 13:29:07,679 :: PID 38128 :: TID 33836 :: database._close_connection :: Line 44 :: DEBUG :: Closed connection to SQLite database\n",
      "2025-12-01 13:29:07,683 :: PID 38128 :: TID 33836 :: database._create_connection :: Line 33 :: DEBUG :: Connected to SQLite database\n",
      "2025-12-01 13:29:07,684 :: PID 38128 :: TID 33836 :: database.read_records :: Line 138 :: DEBUG :: Attempting to execute SELECT SQL statement\n",
      "2025-12-01 13:29:10,453 :: PID 38128 :: TID 33836 :: database._execute :: Line 57 :: DEBUG :: SQL statement executed successfully\n",
      "2025-12-01 13:29:13,153 :: PID 38128 :: TID 33836 :: database._close_connection :: Line 44 :: DEBUG :: Closed connection to SQLite database\n"
     ]
    }
   ],
   "source": [
    "client_data = _get_client_data(client_id)\n",
    "file_data = _get_file_data(client_id, file_id)\n",
    "ardef_data = _get_visa_ardef(file_data[\"file_processing_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"account_interval\"] = pd.cut(\n",
    "    data[\"card_number\"].str.replace(\"*\", \"0\").str.slice(0, 9).astype(int),\n",
    "    ardef_data[\"account_interval\"],\n",
    "    include_lowest=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_interval = pd.Interval(left=0, right=0, closed=\"both\")\n",
    "data[\"account_interval\"] = data[\"account_interval\"].cat.add_categories([fill_interval])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"account_interval\"] = data[\"account_interval\"].where(\n",
    "    data[\"account_interval\"].notna(), fill_interval\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMS_FIELDS: list[Type[CalculatedField]] = [\n",
    "    acquirer_bin,\n",
    "    ardef_country,\n",
    "    authorization_code_valid,\n",
    "    b2b_program_id,\n",
    "    business_mode,\n",
    "    business_transaction_type,\n",
    "    fast_funds,\n",
    "    funding_source,\n",
    "    issuer_bin_8,\n",
    "    issuer_country,\n",
    "    issuer_region,\n",
    "    jurisdiction,\n",
    "    jurisdiction_assigned,\n",
    "    jurisdiction_country,\n",
    "    jurisdiction_region,\n",
    "    nnss_indicator,\n",
    "    processing_code_transaction_type,\n",
    "    product_id,\n",
    "    product_subtype,\n",
    "    reversal_indicator,\n",
    "    source_amount,\n",
    "    source_currency_code_alphabetic,\n",
    "    technology_indicator,\n",
    "    timeliness,\n",
    "    transaction_code_sms,\n",
    "    travel_indicator,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 13:29:20,392 :: PID 38128 :: TID 33836 :: database._create_connection :: Line 33 :: DEBUG :: Connected to SQLite database\n",
      "2025-12-01 13:29:20,392 :: PID 38128 :: TID 33836 :: database.read_records :: Line 138 :: DEBUG :: Attempting to execute SELECT SQL statement\n",
      "2025-12-01 13:29:20,392 :: PID 38128 :: TID 33836 :: database._execute :: Line 57 :: DEBUG :: SQL statement executed successfully\n",
      "2025-12-01 13:29:20,407 :: PID 38128 :: TID 33836 :: database.read_records :: Line 138 :: DEBUG :: Attempting to execute SELECT SQL statement\n",
      "2025-12-01 13:29:20,408 :: PID 38128 :: TID 33836 :: database._execute :: Line 57 :: DEBUG :: SQL statement executed successfully\n",
      "2025-12-01 13:29:21,291 :: PID 38128 :: TID 33836 :: database._close_connection :: Line 44 :: DEBUG :: Closed connection to SQLite database\n",
      "2025-12-01 13:29:21,307 :: PID 38128 :: TID 33836 :: database._create_connection :: Line 33 :: DEBUG :: Connected to SQLite database\n",
      "2025-12-01 13:29:21,308 :: PID 38128 :: TID 33836 :: database.read_records :: Line 138 :: DEBUG :: Attempting to execute SELECT SQL statement\n",
      "2025-12-01 13:29:21,308 :: PID 38128 :: TID 33836 :: database._execute :: Line 57 :: DEBUG :: SQL statement executed successfully\n",
      "2025-12-01 13:29:21,308 :: PID 38128 :: TID 33836 :: database.read_records :: Line 138 :: DEBUG :: Attempting to execute SELECT SQL statement\n",
      "2025-12-01 13:29:21,308 :: PID 38128 :: TID 33836 :: database._execute :: Line 57 :: DEBUG :: SQL statement executed successfully\n",
      "2025-12-01 13:29:22,242 :: PID 38128 :: TID 33836 :: database._close_connection :: Line 44 :: DEBUG :: Closed connection to SQLite database\n",
      "2025-12-01 13:29:22,242 :: PID 38128 :: TID 33836 :: database._create_connection :: Line 33 :: DEBUG :: Connected to SQLite database\n",
      "2025-12-01 13:29:22,242 :: PID 38128 :: TID 33836 :: database.read_records :: Line 138 :: DEBUG :: Attempting to execute SELECT SQL statement\n",
      "2025-12-01 13:29:22,242 :: PID 38128 :: TID 33836 :: database._execute :: Line 57 :: DEBUG :: SQL statement executed successfully\n",
      "2025-12-01 13:29:22,275 :: PID 38128 :: TID 33836 :: database._close_connection :: Line 44 :: DEBUG :: Closed connection to SQLite database\n",
      "2025-12-01 13:29:24,475 :: PID 38128 :: TID 33836 :: database._create_connection :: Line 33 :: DEBUG :: Connected to SQLite database\n",
      "2025-12-01 13:29:24,475 :: PID 38128 :: TID 33836 :: database.read_records :: Line 138 :: DEBUG :: Attempting to execute SELECT SQL statement\n",
      "2025-12-01 13:29:24,475 :: PID 38128 :: TID 33836 :: database._execute :: Line 57 :: DEBUG :: SQL statement executed successfully\n",
      "2025-12-01 13:29:24,507 :: PID 38128 :: TID 33836 :: database._close_connection :: Line 44 :: DEBUG :: Closed connection to SQLite database\n",
      "2025-12-01 13:29:25,178 :: PID 38128 :: TID 33836 :: database._create_connection :: Line 33 :: DEBUG :: Connected to SQLite database\n",
      "2025-12-01 13:29:25,178 :: PID 38128 :: TID 33836 :: database.read_records :: Line 138 :: DEBUG :: Attempting to execute SELECT SQL statement\n",
      "2025-12-01 13:29:25,178 :: PID 38128 :: TID 33836 :: database._execute :: Line 57 :: DEBUG :: SQL statement executed successfully\n",
      "2025-12-01 13:29:25,245 :: PID 38128 :: TID 33836 :: database._close_connection :: Line 44 :: DEBUG :: Closed connection to SQLite database\n"
     ]
    }
   ],
   "source": [
    "fields = []\n",
    "for field in SMS_FIELDS:\n",
    "    calculated_field = field(\n",
    "        client_data,\n",
    "        file_data,\n",
    "        ardef_data,\n",
    "    ).calculate(data, type_record=\"sms\")\n",
    "    calculated_field.name = field.__name__\n",
    "    fields.append(calculated_field)\n",
    "calculated_df = pd.concat(fields, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-01 13:29:26,046 :: PID 38128 :: TID 33836 :: 3581796322.<module> :: Line 1 :: INFO :: Saving Visa Draft calculated fields from SBSA file B6781ADDCFE0CD800BFA2968A6ED2816\n",
      "2025-12-01 13:29:26,046 :: PID 38128 :: TID 33836 :: file.write_parquet :: Line 128 :: DEBUG :: Writing SBSA file B6781ADDCFE0CD800BFA2968A6ED2816 to parquet\n",
      "2025-12-01 13:29:26,046 :: PID 38128 :: TID 33836 :: database._create_connection :: Line 33 :: DEBUG :: Connected to SQLite database\n",
      "2025-12-01 13:29:26,046 :: PID 38128 :: TID 33836 :: database.read_records :: Line 138 :: DEBUG :: Attempting to execute SELECT SQL statement\n",
      "2025-12-01 13:29:26,057 :: PID 38128 :: TID 33836 :: database._execute :: Line 57 :: DEBUG :: SQL statement executed successfully\n",
      "2025-12-01 13:29:26,058 :: PID 38128 :: TID 33836 :: database._close_connection :: Line 44 :: DEBUG :: Closed connection to SQLite database\n"
     ]
    }
   ],
   "source": [
    "log.logger.info(f\"Saving Visa Draft calculated fields from {client_id} file {file_id}\")\n",
    "fs.write_parquet(calculated_df, target_layer, client_id, file_id, subdir=target_subdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[\"sender_reference_number_sms\"].unique()\n",
    "data[\"processing_code\"].str.slice(0, 2).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_df[\"jurisdiction\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{col: calculated_df[col].unique() for col in calculated_df.columns}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
